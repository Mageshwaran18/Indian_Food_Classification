21.1.25

Text Classification:-

     * tf.data --> tf.data API makes it possible to handle large amounts of data, read from different data formats, and 
perform complex transformations.

     * tf.data.DataSet --> The tf.data API introduces a tf.data.Dataset abstraction that represents a sequence of elements, in 
which each element consists of one or more components

     * Batch Size --> Batch size is a hyperparameter that defines the number of samples that will be propagated through the network at once.

     * text_dataset_from_directory

     1. Format & Structure:
        - tf.keras creates a tf.data.Dataset object optimized for TensorFlow operations and streaming
        - sklearn returns simple numpy arrays or pandas dataframes

     2. Memory Efficiency:
        - tf.keras loads data in batches, making it more memory efficient for large datasets
        - sklearn loads all data into memory at once

    * TextVectorization
    * Buffer size --> Buffer size controls how many elements can be prefetched and stored in memory
    * Autotune --> AUTOTUNE lets TensorFlow dynamically adjust the buffer size based on available resources , 
    * I/O  Bottleneck --> I/O (Input/Output) bottlenecks occur when data transfer between storage (disk) and memory 
    * Cache() --> keeps data in memory after first epoch 
    * prefetch () --> overlaps data preprocessing and model execution
    * embeddings --> Used to understand the semantic meaning of words from one to another in a text 

    Adam (Adaptive Moment Estimation):
        * Popular optimization algorithm used for training deep learning models
        * Combines ideas from two other optimizers: RMSprop and Momentum
        * Key features:
            - Adapts learning rates for each parameter
            - Uses estimates of first and second moments of gradients
            - Includes bias correction
            - Good default choice for many deep learning applications
        * Hyperparameters:
            - Learning rate (default: 0.001)
            - Beta1 (default: 0.9) - Exponential decay rate for first moment
            - Beta2 (default: 0.999) - Exponential decay rate for second moment
            - Epsilon (default: 1e-7) - Small constant for numerical stability


------------------------------------------

Nginx and Gunicorn :- 

When deploying a Flask application on an **EC2 instance**, you often use **Nginx** and **Gunicorn** to make your app run smoothly and handle web traffic efficiently. Here‚Äôs a simple explanation:  

### 1Ô∏è‚É£ **Gunicorn (Application Server)**
Think of **Gunicorn** as a waiter in a restaurant. When a customer (user) makes an order (request), the waiter takes it to the chef (Flask app) and brings the food (response) back to the customer.  

üëâ **Why do we need Gunicorn?**  
- Flask has a built-in web server, but it‚Äôs **not good for production** (it‚Äôs slow and can handle only a few users at a time).  
- Gunicorn helps Flask **handle multiple requests** at the same time, making your app **faster and more reliable**.  

### 2Ô∏è‚É£ **Nginx (Web Server & Reverse Proxy)**
Now, imagine **Nginx** as the restaurant‚Äôs **front desk**. It manages incoming customers and directs them to the right waiters (Gunicorn processes).  

üëâ **Why do we need Nginx?**  
- It can handle **thousands of users at once** and efficiently distribute traffic.  
- It acts as a **reverse proxy**, meaning it sits in front of Gunicorn and **forwards requests** to it.  
- It can serve **static files** (like images, CSS, JavaScript) much faster than Gunicorn.  
- It provides **security features**, like preventing direct access to the Flask app.  

### üî• **How They Work Together in Deployment**
1Ô∏è‚É£ A user visits your Flask web app.  
2Ô∏è‚É£ **Nginx** receives the request and forwards it to **Gunicorn**.  
3Ô∏è‚É£ **Gunicorn** runs your Flask app and processes the request.  
4Ô∏è‚É£ The response goes back to **Nginx**, which then sends it to the user.  

This setup ensures **speed, scalability, and security** for your Flask application on EC2. üöÄ
